{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069273ff-9f1e-4abe-8a33-ee5746447acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af1d02a-c6fa-4364-a590-042afacae226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0594ec13-c686-4543-aad4-b5620f63e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class EmailPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and preprocess email text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Tokenize and remove stopwords\n",
    "        words = text.split()\n",
    "        words = [self.stemmer.stem(word) for word in words if word not in self.stop_words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features from email data\"\"\"\n",
    "        # Combine subject and body\n",
    "        df['combined_text'] = df['Subject'].fillna('') + ' ' + df['Body'].fillna('')\n",
    "        \n",
    "        # Clean the combined text\n",
    "        df['cleaned_text'] = df['combined_text'].apply(self.clean_text)\n",
    "        \n",
    "        # Vectorize the text\n",
    "        X = self.vectorizer.fit_transform(df['cleaned_text'])\n",
    "        \n",
    "        # Encode labels\n",
    "        y = self.label_encoder.fit_transform(df['category'])\n",
    "        \n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec480f-94c3-4763-a3ee-b5a666c28c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed8dbc8-66a2-46d8-af02-864a1d371df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# import joblib\n",
    "\n",
    "# class EmailClassifier:\n",
    "#     def __init__(self):\n",
    "#         self.models = {\n",
    "#             'Multinomial_NB': MultinomialNB(),\n",
    "#             'Decision_Tree': DecisionTreeClassifier(random_state=42),\n",
    "#             'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#             'Logistic_Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "#             'SVM': SVC(kernel='linear', random_state=42)\n",
    "#         }\n",
    "#         self.best_model = None\n",
    "#         self.best_accuracy = 0\n",
    "#         self.preprocessor = EmailPreprocessor()\n",
    "    \n",
    "#     def train_models(self, X_train, X_test, y_train, y_test):\n",
    "#         \"\"\"Train all models and find the best one\"\"\"\n",
    "#         results = {}\n",
    "        \n",
    "#         for name, model in self.models.items():\n",
    "#             print(f\"Training {name}...\")\n",
    "            \n",
    "#             # Train the model\n",
    "#             model.fit(X_train, y_train)\n",
    "            \n",
    "#             # Make predictions\n",
    "#             y_pred = model.predict(X_test)\n",
    "            \n",
    "#             # Calculate accuracy\n",
    "#             accuracy = accuracy_score(y_test, y_pred)\n",
    "#             results[name] = {\n",
    "#                 'model': model,\n",
    "#                 'accuracy': accuracy,\n",
    "#                 'classification_report': classification_report(y_test, y_pred)\n",
    "#             }\n",
    "            \n",
    "#             print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "#             # Update best model\n",
    "#             if accuracy > self.best_accuracy:\n",
    "#                 self.best_accuracy = accuracy\n",
    "#                 self.best_model = model\n",
    "#                 self.best_model_name = name\n",
    "        \n",
    "#         return results\n",
    "    \n",
    "#     def save_best_model(self, filepath='best_email_classifier.pkl'):\n",
    "#         \"\"\"Save the best model and preprocessor\"\"\"\n",
    "#         model_data = {\n",
    "#             'model': self.best_model,\n",
    "#             'preprocessor': self.preprocessor,\n",
    "#             'model_name': self.best_model_name,\n",
    "#             'accuracy': self.best_accuracy\n",
    "#         }\n",
    "#         joblib.dump(model_data, filepath)\n",
    "#         print(f\"Best model ({self.best_model_name}) saved with accuracy: {self.best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf990b-62d1-4a5f-81af-7683f39a14c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24aecf2-87e9-478e-b2a8-de4bdeb8b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced model training with better data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "class ImprovedEmailClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'Multinomial_NB': MultinomialNB(alpha=1.0),  # Better alpha value\n",
    "            'Decision_Tree': DecisionTreeClassifier(\n",
    "                random_state=42, \n",
    "                max_depth=10,  # Prevent overfitting\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=5\n",
    "            ),\n",
    "            'Random_Forest': RandomForestClassifier(\n",
    "                n_estimators=100, \n",
    "                random_state=42,\n",
    "                max_depth=10,\n",
    "                min_samples_split=10,\n",
    "                class_weight='balanced'  # Handle imbalanced data\n",
    "            ),\n",
    "            'Logistic_Regression': LogisticRegression(\n",
    "                max_iter=1000, \n",
    "                random_state=42,\n",
    "                class_weight='balanced',  # Important for imbalanced data\n",
    "                C=1.0\n",
    "            ),\n",
    "            'SVM': SVC(\n",
    "                kernel='linear', \n",
    "                random_state=42,\n",
    "                class_weight='balanced',  # Handle imbalanced data\n",
    "                probability=True  # Enable probability predictions\n",
    "            )\n",
    "        }\n",
    "        self.best_model = None\n",
    "        self.best_accuracy = 0\n",
    "        self.preprocessor = ImprovedEmailPreprocessor()\n",
    "    \n",
    "    def check_data_balance(self, y):\n",
    "        \"\"\"Check if data is balanced across categories\"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        print(\"Data Distribution:\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            category = self.preprocessor.label_encoder.inverse_transform([label])[0]\n",
    "            percentage = (count / len(y)) * 100\n",
    "            print(f\"  {category}: {count} samples ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Check if any category is over-represented\n",
    "        max_percentage = max(counts) / len(y) * 100\n",
    "        if max_percentage > 70:\n",
    "            print(f\"⚠️  Warning: Data imbalance detected! {max_percentage:.1f}% in one category\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def train_models(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Train all models with better evaluation\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Check data balance\n",
    "        print(\"Training Data Analysis:\")\n",
    "        self.check_data_balance(y_train)\n",
    "        print(\"\\nTesting Data Analysis:\")\n",
    "        self.check_data_balance(y_test)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Get detailed classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'classification_report': report,\n",
    "                'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "            # Check if model is biased toward one class\n",
    "            pred_unique, pred_counts = np.unique(y_pred, return_counts=True)\n",
    "            if len(pred_unique) == 1:\n",
    "                print(f\"⚠️  WARNING: {name} predicts only one class!\")\n",
    "            else:\n",
    "                print(f\"✅ {name} predicts {len(pred_unique)} different classes\")\n",
    "            \n",
    "            # Update best model (consider balanced accuracy for imbalanced data)\n",
    "            if accuracy > self.best_accuracy and len(pred_unique) > 1:\n",
    "                self.best_accuracy = accuracy\n",
    "                self.best_model = model\n",
    "                self.best_model_name = name\n",
    "        \n",
    "        return results\n",
    "\n",
    "class ImprovedEmailPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        # Better TF-IDF parameters\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=5000, \n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),  # Include bigrams\n",
    "            min_df=2,  # Ignore terms that appear in less than 2 documents\n",
    "            max_df=0.8  # Ignore terms that appear in more than 80% of documents\n",
    "        )\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Enhanced text cleaning\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove special characters but keep some punctuation\n",
    "        text = re.sub(r'[^a-zA-Z\\s!?.]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Tokenize and remove stopwords\n",
    "        words = text.split()\n",
    "        words = [self.stemmer.stem(word) for word in words if word not in self.stop_words and len(word) > 2]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Enhanced feature preparation with better handling\"\"\"\n",
    "        # Combine subject and body with weights\n",
    "        df['combined_text'] = (df['subject'].fillna('') * 2 + ' ' + df['body'].fillna(''))  # Give more weight to subject\n",
    "        \n",
    "        # Clean the combined text\n",
    "        df['cleaned_text'] = df['combined_text'].apply(self.clean_text)\n",
    "        \n",
    "        # Remove empty texts\n",
    "        df = df[df['cleaned_text'].str.len() > 0]\n",
    "        \n",
    "        # Vectorize the text\n",
    "        X = self.vectorizer.fit_transform(df['cleaned_text'])\n",
    "        \n",
    "        # Encode labels\n",
    "        y = self.label_encoder.fit_transform(df['category'])\n",
    "        \n",
    "        print(f\"Features created: {X.shape}\")\n",
    "        print(f\"Categories: {list(self.label_encoder.classes_)}\")\n",
    "        \n",
    "        return X, y, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08f0c9-221f-4cdf-a31f-7402bcee1703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60f5ab9-6c6d-4154-86f7-0bf1c7dd0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_training():\n",
    "    \"\"\"Improved training with better data handling\"\"\"\n",
    "    print(\"🔧 Starting Improved Email Classification Training\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load your email data\n",
    "    try:\n",
    "        df = pd.read_csv('email_data.csv')\n",
    "        print(f\"✅ Loaded {len(df)} emails from dataset\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: email_data.csv not found!\")\n",
    "        print(\"Please make sure your training data file exists.\")\n",
    "        return\n",
    "    \n",
    "    # Check required columns\n",
    "    required_columns = ['subject', 'body', 'category']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"❌ Error: Missing columns: {missing_columns}\")\n",
    "        return\n",
    "    \n",
    "    # Display data info\n",
    "    print(f\"\\nDataset Info:\")\n",
    "    print(f\"Total emails: {len(df)}\")\n",
    "    print(f\"Categories distribution:\")\n",
    "    category_counts = df['category'].value_counts()\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Check for data imbalance\n",
    "    min_category_count = category_counts.min()\n",
    "    max_category_count = category_counts.max()\n",
    "    if max_category_count / min_category_count > 10:\n",
    "        print(\"⚠️  Warning: Severe data imbalance detected!\")\n",
    "        print(\"Consider balancing your dataset or using class weights.\")\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = ImprovedEmailClassifier()\n",
    "    \n",
    "    # Prepare features\n",
    "    try:\n",
    "        X, y, cleaned_df = classifier.preprocessor.prepare_features(df)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in feature preparation: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Split data with stratification to maintain class distribution\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining set: {X_train.shape[0]} emails\")\n",
    "    print(f\"Testing set: {X_test.shape[0]} emails\")\n",
    "    \n",
    "    # Train models and get results\n",
    "    results = classifier.train_models(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Save the best model\n",
    "    if classifier.best_model is not None:\n",
    "        classifier.save_best_model()\n",
    "        \n",
    "        # Test with sample emails\n",
    "        test_sample_classifications(classifier)\n",
    "    else:\n",
    "        print(\"❌ No suitable model found! All models may be biased.\")\n",
    "        \n",
    "    # Print detailed results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    for name, result in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "        print(\"Per-class performance:\")\n",
    "        for class_name in classifier.preprocessor.label_encoder.classes_:\n",
    "            if class_name in result['classification_report']:\n",
    "                f1 = result['classification_report'][class_name]['f1-score']\n",
    "                precision = result['classification_report'][class_name]['precision']\n",
    "                recall = result['classification_report'][class_name]['recall']\n",
    "                print(f\"  {class_name}: F1={f1:.3f}, Precision={precision:.3f}, Recall={recall:.3f}\")\n",
    "    \n",
    "    if classifier.best_model is not None:\n",
    "        print(f\"\\n🏆 Best Model: {classifier.best_model_name}\")\n",
    "        print(f\"🎯 Best Accuracy: {classifier.best_accuracy:.4f}\")\n",
    "    \n",
    "def test_sample_classifications(classifier):\n",
    "    \"\"\"Test the model with known examples\"\"\"\n",
    "    test_emails = [\n",
    "        (\"Free money! Click here now!\", \"Get rich quick! Limited time offer!\", \"spam\"),\n",
    "        (\"Meeting tomorrow at 2 PM\", \"Hi, don't forget our meeting tomorrow\", \"primary\"),\n",
    "        (\"Your order has shipped\", \"Thank you for your purchase. Tracking: 123\", \"updates\"),\n",
    "        (\"Friend posted on Facebook\", \"John posted a new photo\", \"social\"),\n",
    "        (\"Win free iPhone!\", \"Congratulations! You've won! Click to claim\", \"spam\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🧪 Testing with sample emails:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for subject, body, expected in test_emails:\n",
    "        result = classifier.classifier.classify_email(subject, body)\n",
    "        status = \"✅\" if result['category'] == expected else \"❌\"\n",
    "        print(f\"{status} Expected: {expected}, Got: {result['category']} (confidence: {result['confidence']:.3f})\")\n",
    "        print(f\"   Subject: {subject[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec473ea6-66de-4282-86fa-d978232c6810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba8644e-7671-438f-9232-dff292dd9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailClassificationService:\n",
    "    def __init__(self, model_path='best_email_classifier.pkl'):\n",
    "        \"\"\"Load the trained model with error handling\"\"\"\n",
    "        try:\n",
    "            self.model_data = joblib.load(model_path)\n",
    "            self.model = self.model_data['model']\n",
    "            self.preprocessor = self.model_data['preprocessor']\n",
    "            print(f\"✅ Model loaded: {self.model_data.get('model_name', 'Unknown')}\")\n",
    "            print(f\"🎯 Training accuracy: {self.model_data.get('accuracy', 'Unknown')}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"❌ Error: Model file not found! Please train the model first.\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading model: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Category mapping\n",
    "        self.categories = ['spam', 'non_spam', 'primary', 'social', 'updates']\n",
    "    \n",
    "    def classify_email(self, subject, body):\n",
    "        \"\"\"\n",
    "        Enhanced email classification with debugging\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Combine subject and body (give more weight to subject)\n",
    "            combined_text = f\"{subject} {subject} {body}\"  # Subject appears twice for more weight\n",
    "            \n",
    "            # Clean the text\n",
    "            cleaned_text = self.preprocessor.clean_text(combined_text)\n",
    "            \n",
    "            # Debug: Check if text is being cleaned properly\n",
    "            if len(cleaned_text.strip()) == 0:\n",
    "                print(f\"⚠️  Warning: Text became empty after cleaning\")\n",
    "                return {\n",
    "                    'category': 'non_spam',  # Default to non_spam instead of spam\n",
    "                    'confidence': 0.5,\n",
    "                    'is_spam': False,\n",
    "                    'debug_info': 'Empty text after cleaning'\n",
    "                }\n",
    "            \n",
    "            # Vectorize\n",
    "            text_vector = self.preprocessor.vectorizer.transform([cleaned_text])\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.model.predict(text_vector)[0]\n",
    "            \n",
    "            # Get prediction probabilities if available\n",
    "            if hasattr(self.model, 'predict_proba'):\n",
    "                probabilities = self.model.predict_proba(text_vector)[0]\n",
    "                confidence = float(max(probabilities))\n",
    "                \n",
    "                # Debug: Check if model is always predicting the same class\n",
    "                all_probs = {\n",
    "                    cat: float(prob) for cat, prob in zip(self.preprocessor.label_encoder.classes_, probabilities)\n",
    "                }\n",
    "                print(f\"🔍 Debug - All probabilities: {all_probs}\")\n",
    "                \n",
    "            else:\n",
    "                confidence = 1.0\n",
    "                all_probs = None\n",
    "            \n",
    "            # Decode the prediction\n",
    "            category = self.preprocessor.label_encoder.inverse_transform([prediction])[0]\n",
    "            \n",
    "            # Additional spam detection rules (as backup)\n",
    "            spam_keywords = ['free', 'win', 'winner', 'click here', 'limited time', 'urgent', 'congratulations']\n",
    "            text_lower = combined_text.lower()\n",
    "            spam_score = sum(1 for keyword in spam_keywords if keyword in text_lower)\n",
    "            \n",
    "            # If confidence is low and we detect spam keywords, adjust\n",
    "            if confidence < 0.7 and spam_score >= 2:\n",
    "                category = 'spam'\n",
    "                confidence = 0.8\n",
    "            \n",
    "            return {\n",
    "                'category': str(category),\n",
    "                'confidence': confidence,\n",
    "                'is_spam': category == 'spam',\n",
    "                'all_probabilities': all_probs,\n",
    "                'spam_keyword_score': spam_score,\n",
    "                'cleaned_text_length': len(cleaned_text)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Classification error: {e}\")\n",
    "            return {\n",
    "                'category': 'non_spam',  # Default to non_spam, not spam\n",
    "                'confidence': 0.0,\n",
    "                'error': str(e),\n",
    "                'is_spam': False\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676abf81-d943-420a-887d-08bce2ab22eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360ee75-2f79-4950-9c66-9ebdd5953822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d7ff2-3536-4933-a4ae-072511a32c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c097fa4-48cb-4213-b4c7-8f3d9df6fa37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92db05d-1853-41eb-944a-17e0b7703e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f3311-4e1a-41de-8699-cb70a0cfed29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e971bc-1ee4-42dd-9cf0-06fc247eca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "class EmailDatabase:\n",
    "    def __init__(self, host='localhost', user='root', \n",
    "                 password='Mh11@SrA', database='email_management'):\n",
    "        self.connection_params = {\n",
    "            'host': host,\n",
    "            'user': user,\n",
    "            'password': password,\n",
    "            'database': database\n",
    "        }\n",
    "        self.classifier = EmailClassificationService()\n",
    "    \n",
    "    def get_connection(self):\n",
    "        \"\"\"Get database connection\"\"\"\n",
    "        return mysql.connector.connect(**self.connection_params)\n",
    "    \n",
    "    def store_email(self, subject, body, sender_email=None):\n",
    "        \"\"\"Store email in database with classification\"\"\"\n",
    "        try:\n",
    "            # Classify the email\n",
    "            classification = self.classifier.classify_email(subject, body)\n",
    "            \n",
    "            # Connect to database\n",
    "            conn = self.get_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Convert NumPy types to Python native types\n",
    "            confidence_value = float(classification['confidence'])\n",
    "            \n",
    "            # Insert email\n",
    "            query = \"\"\"\n",
    "            INSERT INTO emails (subject, body, sender_email, category, confidence, is_processed)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            values = (\n",
    "                str(subject),\n",
    "                str(body),\n",
    "                str(sender_email) if sender_email else None,\n",
    "                str(classification['category']),\n",
    "                confidence_value,\n",
    "                True\n",
    "            )\n",
    "            \n",
    "            cursor.execute(query, values)\n",
    "            conn.commit()\n",
    "            \n",
    "            email_id = cursor.lastrowid\n",
    "            \n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            print(f\"✅ Email stored with ID: {email_id}\")\n",
    "            print(f\"📧 Classification: {classification['category']}\")\n",
    "            print(f\"🎯 Confidence: {confidence_value:.2f}\")\n",
    "            \n",
    "            return {\n",
    "                'email_id': email_id,\n",
    "                'classification': classification,\n",
    "                'stored': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error storing email: {e}\")\n",
    "            return {'stored': False, 'error': str(e)}\n",
    "    \n",
    "    def get_spam_emails(self):\n",
    "        \"\"\"Get all spam emails\"\"\"\n",
    "        try:\n",
    "            conn = self.get_connection()\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            query = \"SELECT * FROM emails WHERE category = 'spam' ORDER BY created_at DESC\"\n",
    "            cursor.execute(query)\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching spam emails: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_emails_by_category(self, category):\n",
    "        \"\"\"Get emails by specific category\"\"\"\n",
    "        try:\n",
    "            conn = self.get_connection()\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            query = \"SELECT * FROM emails WHERE category = %s ORDER BY created_at DESC LIMIT 20\"\n",
    "            cursor.execute(query, (category,))\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching emails for category {category}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_all_emails(self, limit=50):\n",
    "        \"\"\"Get all emails with limit\"\"\"\n",
    "        try:\n",
    "            conn = self.get_connection()\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            query = \"SELECT * FROM emails ORDER BY created_at DESC LIMIT %s\"\n",
    "            cursor.execute(query, (limit,))\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching all emails: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def manual_cleanup_spam(self, hours_old=1):\n",
    "        \"\"\"Manually cleanup old spam emails\"\"\"\n",
    "        try:\n",
    "            conn = self.get_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Get count before deletion for logging\n",
    "            count_query = \"\"\"\n",
    "            SELECT COUNT(*) FROM emails \n",
    "            WHERE category = 'spam' \n",
    "            AND created_at <= DATE_SUB(NOW(), INTERVAL %s HOUR)\n",
    "            \"\"\"\n",
    "            cursor.execute(count_query, (hours_old,))\n",
    "            count_before = cursor.fetchone()[0]\n",
    "            \n",
    "            if count_before > 0:\n",
    "                # Delete the spam emails\n",
    "                delete_query = \"\"\"\n",
    "                DELETE FROM emails \n",
    "                WHERE category = 'spam' \n",
    "                AND created_at <= DATE_SUB(NOW(), INTERVAL %s HOUR)\n",
    "                \"\"\"\n",
    "                cursor.execute(delete_query, (hours_old,))\n",
    "                conn.commit()\n",
    "                \n",
    "                deleted_count = cursor.rowcount\n",
    "                \n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                \n",
    "                print(f\"🗑️  Cleaned up {deleted_count} old spam emails\")\n",
    "                return deleted_count\n",
    "            else:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                print(\"🧹 No old spam emails to clean up\")\n",
    "                return 0\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during cleanup: {e}\")\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fe721-a46f-4b72-bf3c-40645729a9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e7643-1850-403c-912f-85dfce315208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf606fa-a255-46a2-a069-abec2ef111a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded: Random_Forest\n",
      "🎯 Training accuracy: 0.9489381636477202\n",
      "Complete Email Classification System\n",
      "========================================\n",
      "\n",
      "Options:\n",
      "1. 📝 Classify and store new email\n",
      "2. 🚨 View spam emails\n",
      "3. 📂 View emails by category\n",
      "4. 🗑️  Manual spam cleanup\n",
      "5. 📋 View all emails\n",
      "6. 🚪 Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-6):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter email details:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Subject:  Interview Request for NielsenIQ\n",
      "Body:  Please see attachment for Teams Link (Video Interview)*  Dear Sajjan,  Congratulations on making it to the next stage of the interview process for the Executive, Data Scientist position at NielsenIQ!     We have scheduled an interview appointment for you on Wednesday, July 30, 2025 at 11:45 AM GMT+5:30. Please find the interview invite attached. If you need to reschedule to a different time and/or date, feel free to contact us at   or pearl.silveira@nielseniq.com.  For your reference, here's the link to the job ad: https://jobs.smartrecruiters.com/ni/NielsenIQ/3dd0fbe8-f1a3-4f50-a624-ca2457889557-executive-data-scientist  To help you best prepare for your interview, please refer to our Candidate booklet.pdf. We built this document to help guide you and provide you with more information about our business, our culture, what to expect from your hiring process, and tips from our team to prepare for success.   We're looking forward to meeting you soon and wish you the best of luck!  Sincerely,  Pearl Silveira\n",
      "Sender email (optional):  Pearl Silveira from NielsenIQ <notifications@smartrecruiters.com>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debug - All probabilities: {'Primary': 0.17, 'Promotion': 0.03, 'Social': 0.02, 'Spam': 0.76, 'Updates': 0.02}\n",
      "✅ Email stored with ID: 14\n",
      "📧 Classification: Spam\n",
      "🎯 Confidence: 0.76\n",
      "\n",
      "✅ Email stored successfully!\n",
      "📧 Category: Spam\n",
      "🎯 Confidence: 0.76\n",
      "\n",
      "Options:\n",
      "1. 📝 Classify and store new email\n",
      "2. 🚨 View spam emails\n",
      "3. 📂 View emails by category\n",
      "4. 🗑️  Manual spam cleanup\n",
      "5. 📋 View all emails\n",
      "6. 🚪 Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-6):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 spam emails:\n",
      "🆔 ID: 14\n",
      "📧 Subject: Interview Request for NielsenIQ...\n",
      "⏰ Created: 2025-07-27 18:34:56\n",
      "🎯 Confidence: 0.76\n",
      "------------------------------\n",
      "🆔 ID: 13\n",
      "📧 Subject: You have a new friend request from Priya Sharma...\n",
      "⏰ Created: 2025-07-27 18:25:52\n",
      "🎯 Confidence: 0.55\n",
      "------------------------------\n",
      "🆔 ID: 12\n",
      "📧 Subject: 🔥 Flat 50% Off on All Fashion – Today Only!...\n",
      "⏰ Created: 2025-07-27 18:25:01\n",
      "🎯 Confidence: 0.49\n",
      "------------------------------\n",
      "\n",
      "Options:\n",
      "1. 📝 Classify and store new email\n",
      "2. 🚨 View spam emails\n",
      "3. 📂 View emails by category\n",
      "4. 🗑️  Manual spam cleanup\n",
      "5. 📋 View all emails\n",
      "6. 🚪 Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1-6):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def complete_email_system():\n",
    "    \"\"\"Complete email classification and storage system\"\"\"\n",
    "    \n",
    "    # Initialize database\n",
    "    db = EmailDatabase()\n",
    "    \n",
    "    print(\"Complete Email Classification System\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1. 📝 Classify and store new email\")\n",
    "        print(\"2. 🚨 View spam emails\")\n",
    "        print(\"3. 📂 View emails by category\")\n",
    "        print(\"4. 🗑️  Manual spam cleanup\")\n",
    "        print(\"5. 📋 View all emails\")\n",
    "        print(\"6. 🚪 Exit\")\n",
    "        \n",
    "        choice = input(\"Enter your choice (1-6): \")\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\nEnter email details:\")\n",
    "            subject = input(\"Subject: \")\n",
    "            body = input(\"Body: \")\n",
    "            sender = input(\"Sender email (optional): \") or None\n",
    "            \n",
    "            # Store email with classification\n",
    "            result = db.store_email(subject, body, sender)\n",
    "            \n",
    "            if result['stored']:\n",
    "                classification = result['classification']\n",
    "                print(f\"\\n✅ Email stored successfully!\")\n",
    "                print(f\"📧 Category: {classification['category']}\")\n",
    "                print(f\"🎯 Confidence: {classification['confidence']:.2f}\")\n",
    "                \n",
    "                if classification['is_spam']:\n",
    "                    print(\"⚠️  This spam email will be automatically deleted!\")\n",
    "            else:\n",
    "                print(f\"❌ Error: {result['error']}\")\n",
    "                \n",
    "        elif choice == '2':\n",
    "            spam_emails = db.get_spam_emails()\n",
    "            print(f\"\\nFound {len(spam_emails)} spam emails:\")\n",
    "            \n",
    "            for email in spam_emails[:5]:  # Show first 5\n",
    "                print(f\"🆔 ID: {email['id']}\")\n",
    "                print(f\"📧 Subject: {email['subject'][:50]}...\")\n",
    "                print(f\"⏰ Created: {email['created_at']}\")\n",
    "                print(f\"🎯 Confidence: {email['confidence']:.2f}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "        elif choice == '3':\n",
    "            print(\"\\nAvailable categories: spam, non_spam, primary, social, updates\")\n",
    "            category = input(\"Enter category: \")\n",
    "            \n",
    "            emails = db.get_emails_by_category(category)\n",
    "            print(f\"\\nFound {len(emails)} emails in '{category}' category:\")\n",
    "            \n",
    "            for email in emails[:5]:  # Show first 5\n",
    "                print(f\"🆔 ID: {email['id']}\")\n",
    "                print(f\"📧 Subject: {email['subject'][:50]}...\")\n",
    "                print(f\"🎯 Confidence: {email['confidence']:.2f}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "        elif choice == '4':\n",
    "            hours = input(\"Delete spam older than how many hours? (default: 1): \")\n",
    "            try:\n",
    "                hours = int(hours) if hours else 1\n",
    "            except:\n",
    "                hours = 1\n",
    "                \n",
    "            deleted_count = db.manual_cleanup_spam(hours_old=hours)\n",
    "                \n",
    "        elif choice == '5':\n",
    "            limit = input(\"How many emails to show? (default: 10): \")\n",
    "            try:\n",
    "                limit = int(limit) if limit else 10\n",
    "            except:\n",
    "                limit = 10\n",
    "                \n",
    "            emails = db.get_all_emails(limit=limit)\n",
    "            print(f\"\\nShowing {len(emails)} most recent emails:\")\n",
    "            \n",
    "            for email in emails:\n",
    "                print(f\"🆔 ID: {email['id']}\")\n",
    "                print(f\"📧 Subject: {email['subject'][:50]}...\")\n",
    "                print(f\"📂 Category: {email['category']}\")\n",
    "                print(f\"🎯 Confidence: {email['confidence']:.2f}\")\n",
    "                print(f\"⏰ Created: {email['created_at']}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "        elif choice == '6':\n",
    "            print(\"👋 Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid choice. Please try again.\")\n",
    "\n",
    "# Run the complete system\n",
    "if __name__ == \"__main__\":\n",
    "    complete_email_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2975eb1-1c85-45c2-9d37-9ab07c9019de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe1936-4666-4e6a-bce8-5effe332f9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586cf58-4fd7-43b2-9c85-ddc8bd207ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2ed0d-7af2-400b-ba58-afb4e9918225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
